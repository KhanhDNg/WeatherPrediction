{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">SIT307 - Data Mining and Machine Learning</span>\n",
    "\n",
    "\n",
    "## <span style=\"color:#0b486b\">Machine Learning Challenge</span>\n",
    "\n",
    "##      Rain in Autralia \n",
    "### Group 10 | Data Mining | 18/09/2019\n",
    "***\n",
    "\n",
    "# <span style=\"color:#a00000\">Instructions for Use</span>\n",
    "\n",
    "Please take `Results.csv` from the datasets folder and place it alongside this notebook.\n",
    "\n",
    "`Results.csv` is generated by the previous assessment task.\n",
    "Therefore, it may be regenerated using the provided notebook for the prior assessment task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. <a href=\"#1.-Features Selection\">Features Selection</a>\n",
    "2. <a href=\"#2.-Machine Learning Models\">Machine Learning Challenge</a>\n",
    "3. <a href=\"#2.-Experiments\">Experiments</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import result from Data Preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataset : (114547, 63)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>...</th>\n",
       "      <th>WindDir9am_NNW</th>\n",
       "      <th>WindDir9am_NW</th>\n",
       "      <th>WindDir9am_S</th>\n",
       "      <th>WindDir9am_SE</th>\n",
       "      <th>WindDir9am_SSE</th>\n",
       "      <th>WindDir9am_SSW</th>\n",
       "      <th>WindDir9am_SW</th>\n",
       "      <th>WindDir9am_W</th>\n",
       "      <th>WindDir9am_WNW</th>\n",
       "      <th>WindDir9am_WSW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NSW</td>\n",
       "      <td>0.513064</td>\n",
       "      <td>0.446154</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>0.289062</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.258824</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.449587</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NSW</td>\n",
       "      <td>0.370546</td>\n",
       "      <td>0.494505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.289062</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.497521</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NSW</td>\n",
       "      <td>0.501188</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304688</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.447934</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NSW</td>\n",
       "      <td>0.413302</td>\n",
       "      <td>0.558242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.613223</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NSW</td>\n",
       "      <td>0.610451</td>\n",
       "      <td>0.652747</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.500826</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  State   MinTemp   MaxTemp  Rainfall  WindGustSpeed  WindSpeed9am  \\\n",
       "0   NSW  0.513064  0.446154  0.001632       0.289062      0.211765   \n",
       "1   NSW  0.370546  0.494505  0.000000       0.289062      0.023529   \n",
       "2   NSW  0.501188  0.507692  0.000000       0.304688      0.200000   \n",
       "3   NSW  0.413302  0.558242  0.000000       0.132812      0.105882   \n",
       "4   NSW  0.610451  0.652747  0.002720       0.265625      0.058824   \n",
       "\n",
       "   WindSpeed3pm  Humidity9am  Humidity3pm  Pressure9am  ...  WindDir9am_NNW  \\\n",
       "0      0.258824         0.71         0.22     0.449587  ...               0   \n",
       "1      0.235294         0.44         0.25     0.497521  ...               1   \n",
       "2      0.282353         0.38         0.30     0.447934  ...               0   \n",
       "3      0.082353         0.45         0.16     0.613223  ...               0   \n",
       "4      0.211765         0.82         0.33     0.500826  ...               0   \n",
       "\n",
       "   WindDir9am_NW  WindDir9am_S  WindDir9am_SE  WindDir9am_SSE  WindDir9am_SSW  \\\n",
       "0              0             0              0               0               0   \n",
       "1              0             0              0               0               0   \n",
       "2              0             0              0               0               0   \n",
       "3              0             0              1               0               0   \n",
       "4              0             0              0               0               0   \n",
       "\n",
       "   WindDir9am_SW  WindDir9am_W  WindDir9am_WNW  WindDir9am_WSW  \n",
       "0              0             1               0               0  \n",
       "1              0             0               0               0  \n",
       "2              0             1               0               0  \n",
       "3              0             0               0               0  \n",
       "4              0             0               0               0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get data from csv file\n",
    "data = pd.read_csv('Result.csv')\n",
    "#look at the data size\n",
    "print(f'Size of the dataset : {data.shape}')\n",
    "#have a look first 5 data in dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the Victoria data to apply for Machine Learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>WindDir9am_NNW</th>\n",
       "      <th>WindDir9am_NW</th>\n",
       "      <th>WindDir9am_S</th>\n",
       "      <th>WindDir9am_SE</th>\n",
       "      <th>WindDir9am_SSE</th>\n",
       "      <th>WindDir9am_SSW</th>\n",
       "      <th>WindDir9am_SW</th>\n",
       "      <th>WindDir9am_W</th>\n",
       "      <th>WindDir9am_WNW</th>\n",
       "      <th>WindDir9am_WSW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38659</th>\n",
       "      <td>0.332542</td>\n",
       "      <td>0.329670</td>\n",
       "      <td>0.008705</td>\n",
       "      <td>0.351562</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.457851</td>\n",
       "      <td>0.4864</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38660</th>\n",
       "      <td>0.296912</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>0.289062</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.258824</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.476033</td>\n",
       "      <td>0.4832</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38661</th>\n",
       "      <td>0.420428</td>\n",
       "      <td>0.356044</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.479339</td>\n",
       "      <td>0.5504</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38662</th>\n",
       "      <td>0.353919</td>\n",
       "      <td>0.421978</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.590083</td>\n",
       "      <td>0.5680</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38663</th>\n",
       "      <td>0.510689</td>\n",
       "      <td>0.505495</td>\n",
       "      <td>0.003264</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.431405</td>\n",
       "      <td>0.4544</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MinTemp   MaxTemp  Rainfall  WindGustSpeed  WindSpeed9am  \\\n",
       "38659  0.332542  0.329670  0.008705       0.351562      0.282353   \n",
       "38660  0.296912  0.371429  0.001088       0.289062      0.211765   \n",
       "38661  0.420428  0.356044  0.001632       0.281250      0.235294   \n",
       "38662  0.353919  0.421978  0.000544       0.250000      0.082353   \n",
       "38663  0.510689  0.505495  0.003264       0.421875      0.329412   \n",
       "\n",
       "       WindSpeed3pm  Humidity9am  Humidity3pm  Pressure9am  Pressure3pm  ...  \\\n",
       "38659      0.329412         0.71         0.37     0.457851       0.4864  ...   \n",
       "38660      0.258824         0.66         0.47     0.476033       0.4832  ...   \n",
       "38661      0.211765         0.82         0.42     0.479339       0.5504  ...   \n",
       "38662      0.235294         0.60         0.33     0.590083       0.5680  ...   \n",
       "38663      0.435294         0.74         0.40     0.431405       0.4544  ...   \n",
       "\n",
       "       WindDir9am_NNW  WindDir9am_NW  WindDir9am_S  WindDir9am_SE  \\\n",
       "38659               0              0             0              0   \n",
       "38660               0              0             0              0   \n",
       "38661               0              0             0              0   \n",
       "38662               0              0             0              0   \n",
       "38663               1              0             0              0   \n",
       "\n",
       "       WindDir9am_SSE  WindDir9am_SSW  WindDir9am_SW  WindDir9am_W  \\\n",
       "38659               0               0              0             1   \n",
       "38660               0               0              0             0   \n",
       "38661               0               0              0             0   \n",
       "38662               0               0              0             0   \n",
       "38663               0               0              0             0   \n",
       "\n",
       "       WindDir9am_WNW  WindDir9am_WSW  \n",
       "38659               0               0  \n",
       "38660               1               0  \n",
       "38661               0               1  \n",
       "38662               0               0  \n",
       "38663               0               0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VIC = data[lambda df:(df.State == 'VIC')]\n",
    "VIC = VIC.drop(['State'], axis = 1)\n",
    "VIC.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split features and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = VIC.drop(['RainTomorrow'], axis = 1)\n",
    "target = VIC['RainTomorrow']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Features Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SelectKBest() function to choose 10 features that have the most affect to target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  6  7  8  9 11 12 48]\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "def is_feature_discrete(name):\n",
    "    \"\"\"\n",
    "    Returns whether a column from the dataset is discrete.\n",
    "\n",
    "    name: The column name.\n",
    "    \"\"\"\n",
    "    if name == 'RainToday':\n",
    "        return True\n",
    "    if name.startswith('WindGustDir'):\n",
    "        return True\n",
    "    if name.startswith('WindDir'):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_discrete_mask(columns):\n",
    "    \"\"\"\n",
    "    Returns a boolean mask for use with mutual_info_classif\n",
    "    from the Victoria Rain dataset.\n",
    "\n",
    "    name: The column names.\n",
    "    \"\"\"\n",
    "    return [is_feature_discrete(name) for name in columns]\n",
    "\n",
    "# Select the K-Best features.\n",
    "new = SelectKBest(functools.partial(mutual_info_classif,\n",
    "                                    discrete_features=get_discrete_mask(features),\n",
    "                                    random_state=1234),\n",
    "                  k=10)\n",
    "new = SelectKBest(mutual_info_classif, k=10)\n",
    "new.fit(features, target)\n",
    "\n",
    "# Generate new feature vectors.\n",
    "X = new.transform(features)\n",
    "print(new.get_support(indices=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MaxTemp', 'Rainfall', 'WindGustSpeed', 'Humidity9am', 'Humidity3pm',\n",
       "       'Pressure9am', 'Pressure3pm', 'Temp3pm', 'RainToday', 'WindDir9am_N'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_index = new.get_support(indices=True)\n",
    "selected_features = features.columns\n",
    "selected_features = selected_features[feature_index]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get best 10 features index <br />\n",
    "Create new DataFrame to store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>WindDir9am_N</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38659</th>\n",
       "      <td>0.329670</td>\n",
       "      <td>0.008705</td>\n",
       "      <td>0.351562</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.457851</td>\n",
       "      <td>0.4864</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38660</th>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>0.289062</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.476033</td>\n",
       "      <td>0.4832</td>\n",
       "      <td>0.353333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38661</th>\n",
       "      <td>0.356044</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.479339</td>\n",
       "      <td>0.5504</td>\n",
       "      <td>0.328889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38662</th>\n",
       "      <td>0.421978</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.590083</td>\n",
       "      <td>0.5680</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38663</th>\n",
       "      <td>0.505495</td>\n",
       "      <td>0.003264</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.431405</td>\n",
       "      <td>0.4544</td>\n",
       "      <td>0.502222</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MaxTemp  Rainfall  WindGustSpeed  Humidity9am  Humidity3pm  \\\n",
       "38659  0.329670  0.008705       0.351562         0.71         0.37   \n",
       "38660  0.371429  0.001088       0.289062         0.66         0.47   \n",
       "38661  0.356044  0.001632       0.281250         0.82         0.42   \n",
       "38662  0.421978  0.000544       0.250000         0.60         0.33   \n",
       "38663  0.505495  0.003264       0.421875         0.74         0.40   \n",
       "\n",
       "       Pressure9am  Pressure3pm   Temp3pm  RainToday  WindDir9am_N  \\\n",
       "38659     0.457851       0.4864  0.311111          1             0   \n",
       "38660     0.476033       0.4832  0.353333          0             0   \n",
       "38661     0.479339       0.5504  0.328889          0             0   \n",
       "38662     0.590083       0.5680  0.420000          0             0   \n",
       "38663     0.431405       0.4544  0.502222          1             0   \n",
       "\n",
       "       RainTomorrow  \n",
       "38659             0  \n",
       "38660             0  \n",
       "38661             0  \n",
       "38662             1  \n",
       "38663             0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = VIC[selected_features][:]\n",
    "new_data['RainTomorrow'] = VIC['RainTomorrow']\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(new_data['RainTomorrow'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 10-fold cross validation to evaluate result of models <br />\n",
    "Report the following scores:\n",
    "> Accuracy <br />\n",
    "> F-Score <br />\n",
    "> Precision <br />\n",
    "> Recall <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(model):\n",
    "    # Using 10-fold cross validation calcualte the mean report scores.\n",
    "    kfold = KFold(n_splits=10, random_state=23)\n",
    "    \n",
    "    Accuracy = cross_val_score(model, X, Y, cv=kfold, scoring='accuracy')\n",
    "    print(\"Accuracy mean : {}\".format(Accuracy.mean()))\n",
    "    \n",
    "    F_Score = cross_val_score(model, X, Y, cv=kfold, scoring='f1_weighted')\n",
    "    print(\"F-Score mean : {}\".format(F_Score.mean()))\n",
    "\n",
    "    Precision = cross_val_score(model, X, Y, cv=kfold, scoring='precision_macro')\n",
    "    print(\"Precision mean : {}\".format(Precision.mean()))\n",
    "\n",
    "    Recall = cross_val_score(model, X, Y, cv=kfold, scoring='recall_macro')\n",
    "    print(\"Recall mean : {}\".format(Recall.mean()))\n",
    "    \n",
    "#     score = np.array([0, 0, 0, 0])\n",
    "#     score[0] = Scores_kfoldt1.mean()\n",
    "#     score[1] = Scores_kfold2.mean()\n",
    "#     score[2] = Scores_kfold3.mean()\n",
    "#     score[3] = Scores_kfold4.mean()\n",
    "    \n",
    "    return Accuracy.mean(), F_Score.mean(), Precision.mean(), Recall.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "svm_pipeline = Pipeline(steps=[('svm', SVC(kernel='rbf', gamma = 'auto'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khanh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy mean : 0.8395029143297041\n",
      "F-Score mean : 0.823687828306787\n",
      "Precision mean : 0.8075095765795568\n",
      "Recall mean : 0.7015716453348385\n"
     ]
    }
   ],
   "source": [
    "accuracy, f_score, precision, recall = report(svm_pipeline)\n",
    "SVM_Score = np.array([accuracy, f_score, precision, recall])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeclf = DecisionTreeClassifier(random_state=1)\n",
    "parameterstree = {'max_depth':range(1,15)}\n",
    "clftree = GridSearchCV(treeclf, parameterstree, cv=10,scoring = 'accuracy')\n",
    "\n",
    "# Fit our training data\n",
    "clftree.fit(X, Y)\n",
    "clftree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(max_depth=6, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khanh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy mean : 0.8356921129164551\n",
      "F-Score mean : 0.8248501950189919\n",
      "Precision mean : 0.7822225299131935\n",
      "Recall mean : 0.7136561997395311\n"
     ]
    }
   ],
   "source": [
    "accuracy, f_score, precision, recall = report(DT)\n",
    "DT_Score = np.array([accuracy, f_score, precision, recall])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 kNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 9, 'weights': 'distance'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "parametersknn = {'n_neighbors': range(3,10),'weights':('uniform','distance')}\n",
    "knnclf = KNeighborsClassifier()\n",
    "clfknn = GridSearchCV(knnclf, parametersknn, cv = 10, scoring = 'accuracy')\n",
    "clfknn.fit(X,Y)\n",
    "clfknn.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 8, weights = 'distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khanh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy mean : 0.8337671405657561\n",
      "F-Score mean : 0.8252367646826662\n",
      "Precision mean : 0.7763593423603801\n",
      "Recall mean : 0.7218927324052286\n"
     ]
    }
   ],
   "source": [
    "accuracy, f_score, precision, recall = report(knn)\n",
    "KNN_Score = np.array([accuracy, f_score, precision, recall])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Logistic Regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100000.0, 'solver': 'sag'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "parameterslrc = {'C' : (1e2, 1e5,1e20),\n",
    "                'solver': ('newton-cg','lbfgs', 'liblinear', 'sag', 'saga')}\n",
    "knnlrc = LogisticRegression(max_iter=1000)\n",
    "clflrc = GridSearchCV(knnlrc,parameterslrc,cv = 10,scoring = 'accuracy')\n",
    "clflrc.fit(X,Y)\n",
    "clflrc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression(C=1e2, solver = 'liblinear', max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khanh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy mean : 0.8418513041191901\n",
      "F-Score mean : 0.8324593479021424\n",
      "Precision mean : 0.7938255861798156\n",
      "Recall mean : 0.7285917577672909\n"
     ]
    }
   ],
   "source": [
    "accuracy, f_score, precision, recall = report(LR)\n",
    "LR_Score = np.array([accuracy, f_score, precision, recall])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30), alpha = 0.01, momentum = 0.1, max_iter = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khanh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy mean : 0.8435071052256363\n",
      "F-Score mean : 0.834193117374558\n",
      "Precision mean : 0.793550363534046\n",
      "Recall mean : 0.7322783076580841\n"
     ]
    }
   ],
   "source": [
    "accuracy, f_score, precision, recall = report(mlp)\n",
    "NN_Score = np.array([accuracy, f_score, precision, recall])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a DataFrame of score mean.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = pd.DataFrame([SVM_Score, DT_Score, KNN_Score, LR_Score, NN_Score], columns=('Accuracy', 'F-Score', 'Precision', 'Recall'))\n",
    "score = score.rename(index={0: 'SVM', 1: 'Decision Tree', 2: 'k-NN', 3: 'Logistic Regression', 4: 'Neural Network'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sort the result by descending accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = score.sort_values(['Accuracy'], ascending=[False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sketch a line graph to compare result of 5 models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x138c65c4b08>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "score.plot(rot=90, figsize = (10, 8), title = 'Score', fontsize = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Cohen's Kappa Score\n",
    "\n",
    "The following cell calculates the values Cohen's Kappa Score using 10-fold cross validation.\n",
    "\n",
    "New classifiers have been initialized with the same parameters as the classifiers used within the previous sections and\n",
    "the Kappa score is calculated for all pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing dt and lreg\n",
      "[0.6278184496075647, 0.6204528636431015, 0.6471986812717019, 0.6927401529298614, 0.6402932502895873, 0.5291301251677909, 0.5567755078446366, 0.6788702150471252, 0.6605160697320439, 0.7154255603129442]\n",
      "Mean Cohen's kappa score: 0.6369220875846358\n",
      "\n",
      "Comparing dt and knn\n",
      "[0.5444329671217776, 0.5624455916003155, 0.6481681562212959, 0.6616875745845965, 0.6241983447891937, 0.5191600978783736, 0.5830835235205636, 0.6136713807951817, 0.6014802327035882, 0.6436447719195695]\n",
      "Mean Cohen's kappa score: 0.6001972641134455\n",
      "\n",
      "Comparing dt and svm\n",
      "[0.6152975847213991, 0.6063314634083194, 0.5743722509157481, 0.6673310122773809, 0.5589449853707158, 0.21355503486454686, 0.520458212053304, 0.6528885127611243, 0.5924541730902455, 0.686954209783029]\n",
      "Mean Cohen's kappa score: 0.5688587439245814\n",
      "\n",
      "Comparing dt and mlpnn\n",
      "[0.6168368322811983, 0.6051355270111934, 0.7005612520849274, 0.6955371984444773, 0.6793732141744402, 0.510275366847308, 0.5729813767228757, 0.6707396042223092, 0.671142541841242, 0.711572702998317]\n",
      "Mean Cohen's kappa score: 0.6434155616628288\n",
      "\n",
      "Comparing lreg and knn\n",
      "[0.6676336275682455, 0.662097149135359, 0.6885902538759918, 0.7451021274162264, 0.7434931341771058, 0.661090530855776, 0.626401467391249, 0.7200394018218673, 0.6808931175534972, 0.7231395316702738]\n",
      "Mean Cohen's kappa score: 0.6918480341465593\n",
      "\n",
      "Comparing lreg and svm\n",
      "[0.7900967469215746, 0.7235800424316455, 0.75540554120338, 0.7705208913880776, 0.769545295565887, 0.2773369558750095, 0.5852550278286723, 0.8472712876441649, 0.7930478582175201, 0.8160506276426569]\n",
      "Mean Cohen's kappa score: 0.7128110274718588\n",
      "\n",
      "Comparing lreg and mlpnn\n",
      "[0.8321333165364839, 0.8844442068916895, 0.8224350576220878, 0.83574098762701, 0.8568066108992275, 0.753714492697566, 0.8382133645995434, 0.817743903738924, 0.8674179901685376, 0.8811465551025882]\n",
      "Mean Cohen's kappa score: 0.8389796485883657\n",
      "\n",
      "Comparing knn and svm\n",
      "[0.7078363649489996, 0.7071682084827715, 0.6484135318955282, 0.6934733456896238, 0.6913028117286137, 0.29092464267046636, 0.5741356880515958, 0.6972285572187892, 0.7135020730982413, 0.7280758119111502]\n",
      "Mean Cohen's kappa score: 0.645206103569578\n",
      "\n",
      "Comparing knn and mlpnn\n",
      "[0.6976597346873822, 0.711843361457579, 0.7409838016335402, 0.7482354926718404, 0.7723209237762966, 0.7233186729434058, 0.663428292767406, 0.7576219789385057, 0.6835134349592737, 0.7538589457940306]\n",
      "Mean Cohen's kappa score: 0.725278463962926\n",
      "\n",
      "Comparing svm and mlpnn\n",
      "[0.7735784607335792, 0.7665853448227504, 0.7903733635125678, 0.739754241121782, 0.5844744701801641, 0.21431685364641162, 0.5418698979297958, 0.8114722950678497, 0.8266027062743742, 0.8147639871455907]\n",
      "Mean Cohen's kappa score: 0.6863791620434865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# A tuple of classifier (name, classifier) tuples.\n",
    "# This tuple uses the parameters as found prior, using SelectKBest.\n",
    "example_classifiers = (('dt', DecisionTreeClassifier(max_depth=6, random_state=1)),\n",
    "                       ('lreg', LogisticRegression(C=1e2, solver = 'liblinear', max_iter=1000)),\n",
    "                       ('knn', KNeighborsClassifier(n_neighbors = 8, weights = 'distance')),\n",
    "                       ('svm', SVC(kernel='rbf', gamma = 'auto')),\n",
    "                       ('mlpnn', MLPClassifier(hidden_layer_sizes=(30,30,30), alpha = 0.01, momentum = 0.1, max_iter = 1000)))\n",
    "\n",
    "def kappa_kfold_report(features, classes, model_1, model_2):\n",
    "    \"\"\"\n",
    "    Generates a 10-fold cross validation report for Cohen's Kappa.\n",
    "    This is a measure of inter-rater reliability\n",
    "    i.e. How the classifier's results correlate.\n",
    "    \n",
    "    features: Rows of features to classify.\n",
    "    classes: The true class of the rows.\n",
    "    model_1: The first model to compare.\n",
    "    model_2: The second model to compare.\n",
    "    return: Cohen's Kappa score for each train-test split.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    ten_fold = KFold(n_splits=10)\n",
    "\n",
    "    for test, train in ten_fold.split(features, classes):\n",
    "        # Each of these classifiers is cloned each iteration to ensure\n",
    "        # that any state mutations are confined to the iteration they\n",
    "        # were first run within.\n",
    "        model_1_clone = clone(model_1)\n",
    "        model_2_clone = clone(model_2)\n",
    "        model_1_clone.fit(features[train], classes[train])\n",
    "        model_1_result = model_1_clone.predict(features[test])\n",
    "        model_2_clone.fit(features[train], classes[train])\n",
    "        model_2_result = model_2_clone.predict(features[test])\n",
    "        results.append(cohen_kappa_score(model_1_result, model_2_result))\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_kappa_kfold_report(features, classes, model_1, model_2):\n",
    "    \"\"\"\n",
    "    Prints a report describing the values of a 10-fold cross validation\n",
    "    for Cohen's Kappa score and their mean value.\n",
    "    \n",
    "    features: Rows of features to classify.\n",
    "    classes: The true class of the rows.\n",
    "    model_1: The first model to compare.\n",
    "    model_2: The second model to compare.\n",
    "    \"\"\"\n",
    "    print(f'Comparing {model_1[0]} and {model_2[0]}')\n",
    "    model_1 = model_1[1]\n",
    "    model_2 = model_2[1]\n",
    "    results = kappa_kfold_report(features, classes, model_1, model_2)\n",
    "    print(results)\n",
    "    print(f'Mean Cohen\\'s kappa score: {np.mean(results)}\\n')\n",
    "\n",
    "# Generate the unique classifier pairs and print the Kappa values for 10-fold cross validation\n",
    "# also print the mean Kappa value.\n",
    "for i in range(len(example_classifiers)):\n",
    "    for j in range(i+1, len(example_classifiers)):\n",
    "        print_kappa_kfold_report(X, Y, example_classifiers[i], example_classifiers[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Ensemble Methods (Voting Classifier)\n",
    "\n",
    "Upon reviewing the values for Cohen's Kappa score we can see quite high inter-rater\n",
    "agreement which is further demonstrated by the fact that these VotingClassifiers\n",
    "do not appear to significantly boost the classification's accuracy.\n",
    "\n",
    "First we take the three simplest algorithms and attempt to achieve a consensus, voting\n",
    "using the highest predicted class probabilities (`voting='soft'`).\n",
    "\n",
    "The `voting='soft'` parameter is recommended within the scikit-learn documentation\n",
    "for well-calibrated classifiers such as those which were trained within the previous sections.\n",
    "Therefore, soft-probabilistic voting was chosen for this classifier.\n",
    "\n",
    "This classifier runs quite quickly on the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khanh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy mean : 0.8443538659962655\n",
      "F-Score mean : 0.8337460869132999\n",
      "Precision mean : 0.8014438691263148\n",
      "Recall mean : 0.7257854439716571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# A voting classifier using the argmax of predicted class probabilities (voting='soft').\n",
    "# This is recommended within the sklearn VotingClassifier documentation,\n",
    "# for well-calibrated classifiers, such as these.\n",
    "votingclassif = VotingClassifier((('dt', DecisionTreeClassifier(max_depth=6, random_state=1)),\n",
    "                                  ('lreg', LogisticRegression(C=1e2, solver = 'liblinear', max_iter=1000)),\n",
    "                                  ('knn', KNeighborsClassifier(n_neighbors = 9, weights = 'distance'))),\n",
    "                                  voting='soft')\n",
    "\n",
    "accuracy, f_score, precision, recall = report(votingclassif)\n",
    "VOTING_score = np.array([accuracy, f_score, precision, recall])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we may take all five classifiers and combine these into a single VotingClassifier.\n",
    "This does not significantly improve the accuracy (these classifiers still have not achieved 85% accuracy or higher).\n",
    "\n",
    "Please note that this ensemble classifier is extremely slow to run (it may take multiple hours on some machines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khanh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-7d3568f3d6d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m                                   voting='soft')\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvotingclassif5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mFIVEVOTING_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-f48482d63cf8>\u001b[0m in \u001b[0;36mreport\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mAccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy mean : {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    388\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    391\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 236\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mtransformed_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mle_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformed_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m     66\u001b[0m                 delayed(_parallel_fit_estimator)(clone(clf), X, y,\n\u001b[0;32m     67\u001b[0m                                                  sample_weight=sample_weight)\n\u001b[1;32m---> 68\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclfs\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'drop'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             )\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\u001b[0m in \u001b[0;36m_parallel_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight)\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    256\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# A voting classifier using the argmax of predicted class probabilities (voting='soft').\n",
    "# This is recommended within the sklearn VotingClassifier documentation,\n",
    "# for well-calibrated classifiers, such as these.\n",
    "votingclassif5 = VotingClassifier((('dt', DecisionTreeClassifier(max_depth=6, random_state=1)),\n",
    "                       ('lreg', LogisticRegression(C=1e2, solver = 'liblinear', max_iter=1000)),\n",
    "                       ('knn', KNeighborsClassifier(n_neighbors = 8, weights = 'distance')),\n",
    "                       ('svm', SVC(kernel='rbf', gamma = 'auto', probability = True)),\n",
    "                       ('mlpnn', MLPClassifier(hidden_layer_sizes=(30,30,30), alpha = 0.01, momentum = 0.1, max_iter = 1000))),\n",
    "                                  voting='soft')\n",
    "\n",
    "accuracy, f_score, precision, recall = report(votingclassif5)\n",
    "FIVEVOTING_score = np.array([accuracy, f_score, precision, recall])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
